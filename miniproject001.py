# -*- coding: utf-8 -*-
"""miniproject001.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GOgnHTh9zhQsiRB_5uMh3UorCHxNGWh_
"""

import pandas as pd

song= pd.read_csv("/content/fma-rock-vs-hiphop.csv")

echonest_metrics=pd.read_json("/content/echonest-metrics.json")

song.head()

echonest_metrics.head()

tracks = pd.merge(left = song[['track_id', 'genre_top']], right=echonest_metrics, on='track_id')

tracks.head()

tracks.info()

# Pairwise relationships between continuous variables
corr_metrics = tracks.corr()
corr_metrics.style.background_gradient()

# Normalizing the feature data
features = tracks.drop(['genre_top', 'track_id'], axis = 1)

labels = tracks['genre_top']

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_train_features = scaler.fit_transform(features)

# Commented out IPython magic to ensure Python compatibility.
#  Principal Component Analysis on our scaled data
# %matplotlib inline
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
pca = PCA()
pca.fit(scaled_train_features)
exp_variance = pca.explained_variance_ratio_
exp_variance

fig, ax = plt.subplots()
ax.bar(range(pca.n_components_),exp_variance)
ax.set_xlabel('Principal Component #')
plt.show()

# Further visualization of PCA
import numpy as np
cum_exp_variance = np.cumsum(exp_variance)
cum_exp_variance

fig, ax = plt.subplots()
ax.plot(range(8),cum_exp_variance)
ax.axhline(y=0.9, linestyle='--')
plt.show()

n_components = 7
pca = PCA(n_components, random_state=10)
pca.fit(scaled_train_features)
pca_projection = pca.transform(scaled_train_features)

pca_projection.shape

# Train a decision tree to classify genre
from sklearn.model_selection import train_test_split
train_features, test_features, train_labels, test_labels = train_test_split(pca_projection, labels, stratify = labels)

from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(random_state = 10)
tree.fit(train_features, train_labels)

pred_labels_tree = tree.predict(test_features)

from sklearn.metrics import accuracy_score
accuracy_score(test_labels, pred_labels_tree)

labels.value_counts()

from sklearn.metrics import confusion_matrix
confusion_matrix(test_labels, pred_labels_tree)

# Compare our decision tree to a logistic regression
from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression(random_state = 10)
logreg.fit(train_features, train_labels)
pred_labels_logit = logreg.predict(test_features)

from sklearn.metrics import classification_report
class_rep_tree = classification_report(test_labels, pred_labels_tree)
class_rep_log = classification_report(test_labels, pred_labels_logit)

print("Decision Tree: \n", class_rep_tree)
print("Logistic Regression: \n", class_rep_log)

# Balance our data for greater performance
hop_only = tracks.loc[tracks['genre_top'] == 'Hip-Hop']
rock_only = tracks.loc[tracks['genre_top'] == 'Rock']
rock_only.head()

rock_only.shape, hop_only.shape

rock_only = rock_only.sample(n= hop_only.shape[0])
rock_only.shape, hop_only.shape

rock_hop_bal = pd.concat([rock_only, hop_only])
rock_hop_bal.shape

features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) 
labels = rock_hop_bal['genre_top']
pca_projection = pca.fit_transform(scaler.fit_transform(features))
train_features, test_features, train_labels, test_labels = train_test_split(pca_projection,
                                                                            labels,
                                                                            stratify = labels,
                                                                            random_state=10)

# Does balancing our dataset improve model bias?
tree = DecisionTreeClassifier(random_state=10)
tree.fit(train_features, train_labels)
pred_labels_tree = tree.predict(test_features)

logreg = LogisticRegression(random_state = 10)
logreg.fit(train_features, train_labels)
pred_labels_logit = logreg.predict(test_features)

print("Decision Tree: \n", classification_report(test_labels, pred_labels_tree))
print("Logistic Regression: \n", classification_report(test_labels, pred_labels_logit))

from sklearn.model_selection import KFold, cross_val_score

# Set up our K-fold cross-validation
kf=KFold(n_splits=10)

tree = DecisionTreeClassifier(random_state=10)
logreg = LogisticRegression(random_state=10)

# Train our models using KFold cv
tree_score = cross_val_score(tree, pca_projection, labels, cv=kf)
logit_score = cross_val_score(logreg, pca_projection, labels, cv=kf)

# Print the mean of each array of scores
print("Decision Tree:", np.mean(tree_score), "Logistic Regression:", np.mean(logit_score))